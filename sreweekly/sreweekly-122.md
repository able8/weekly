## [SRE Weekly Issue #122](https://sreweekly.com/sre-weekly-issue-122/) - May 20, 2018
### Articles

1. [Rapid response: how we fixed our on call process to avoid engineer burnout](https://blog.intercom.com/rapid-response-how-we-developed-an-on-call-team-at-intercom/)

    After adopting a “full ownership” philosophy, this company faced burnout, with five or more separate developers on call simultaneously. Read about their awesome solution involving a shared on-call rotation staffed entirely by volunteers, spurred by the incentive of extra compensation.Brian Scanlan — Intercom
1. [Google Cloud Platform Blog: SRE vs. DevOps: competing standards or close friends?](http://feedproxy.google.com/~r/ClPlBl/~3/g94SC2VnRd8/SRE-vs-DevOps-competing-standards-or-close-friends.html)

    Liz Fong-Jones and Seth Vargo — Google
1. [Making LinkedIn’s Organic Feed Handle Peak Traffic](https://engineering.linkedin.com/blog/2018/05/making-linkedin-s-organic-feed-handle-peak-traffic)

    After a load test uncovered a scaling issue, they dug deep, finding issues with garbage collection settings, cascading failures, and an overeager retry strategy.Val Markovic — LinkedIn
1. [7 Tips to Get New Engineers Ready to Be On-Call](https://www.opsgenie.com/blog/7-tips-to-get-new-engineers-ready-to-be-on-call)

    These tips cover the basics and will be especially useful for teams onboarding engineers that have never been on-call before.
1. [Just Culture & High Reliability: The Initial Approach](http://www.jems.com/ems-insider/articles/2018/may/just-culture-high-reliability-buy-in-commitment-and-trust.html)

    This article examines a case study of an EMS company attempting to adopt a just culture policy. There’s a great discussion of why it’s not a good idea to lay blame on individuals when systemic problems may be far more important. Larry Boxman and Paul LeSage — JEMS (Journal of Emergency Medical Services)
1. [SRE@Xero: Managing Incidents Part III](https://devblog.xero.com/sre-xero-managing-incidents-part-iii-86f88c917006)

    In this third and final article in a series, Xero lays out their process for analyzing incidents after the fact. Thanks to the Xero folks for being so open about your processes and for taking the time to write these articles!Karthik Nilakant — Xero
1. [Want to Debug Latency?](https://medium.com/observability/want-to-debug-latency-7aa48ecbe8f7)

    I like the nifty heat maps with example distributed traces. Neat idea!JBD — Google
### Outages

1. [Sutter Health](http://www.sacbee.com/news/local/health-and-medicine/article211253069.html)
1. [Fortnite (incident analysis)](http://www.epicgames.com/fortnite/en-US/news/postmortem-of-service-outage-4-12)
    I really love how deep and technical Fortnite is with their incident analysis articles! Here’s one for their outage in mid-april.
The Epic Team
1. [Google Compute Engine (us-east4 region)](https://status.cloud.google.com/incident/compute/18004#18004001)
1. [Atlassian Statuspage](https://metastatuspage.com/incidents/mm2j66zm4mdd)
1. [Roku](https://www.cnet.com/news/roku-devices-suffered-outage-tuesday-now-fixed/)
1. [Hulu](http://www.newsweek.com/hulu-down-not-working-error-code-bya-403-007-location-not-available-outage-921688)

### [ << Prev ](sreweekly-121.md) ------------- [ Next >> ](sreweekly-123.md)